# ‚ò†Ô∏è Chaos Engineering ‚Äî Complete Guide for SRE Architects

## üìå What is Chaos Engineering?

> Chaos Engineering is the discipline of **experimenting on a system** in production (or near-prod) to build **confidence in its resilience**.

You intentionally inject failures (network latency, pod crashes, CPU exhaustion, etc.) to answer:
> *‚ÄúWill the system still behave as expected under turbulent conditions?‚Äù*

---

## üéØ Goals of Chaos Engineering

- Validate **resilience** of architecture under failure
- Discover unknown **failure modes** before users do
- Enforce **SLO-based alerts and fallback strategies**
- **Quantify blast radius** and auto-healing mechanisms

---

## üß± Core Principles

| Principle                  | Explanation                                           |
|---------------------------|-------------------------------------------------------|
| Define a steady state     | E.g., ‚ÄúCheckout API is available 99.9% of the time‚Äù  |
| Hypothesize disruption    | E.g., ‚ÄúIf we kill a DB pod, app should recover‚Äù      |
| Introduce chaos           | E.g., delay API responses, block DNS, kill node      |
| Observe and measure       | E.g., Prometheus + alerting + tracing                |
| Automate & repeat         | Build it into CI/CD or weekly chaos workflows        |

---

## üõ†Ô∏è Common Chaos Scenarios

| Layer         | Examples                                         |
|---------------|--------------------------------------------------|
| Network       | Packet loss, latency, dropped traffic            |
| Compute       | Pod/VM/node crash, CPU hog, memory leak          |
| Disk          | I/O latency, full disk, corrupted volume         |
| API           | High error rate, slow responses                  |
| DNS           | Failure to resolve, blackhole external service   |
| Load Balancer | Misrouting, region down                          |

---

## üß™ Chaos Tools You Should Know

| Tool            | Features                                         |
|------------------|--------------------------------------------------|
| **LitmusChaos**  | CNCF project, k8s-native chaos workflows         |
| **Gremlin**      | SaaS tool, enterprise-grade chaos injection      |
| **AWS FIS**      | Fault Injection Simulator, native to AWS         |
| **Chaos Mesh**   | K8s CRDs for powerful fault scenarios            |
| **Toxiproxy**    | Network proxy to simulate latency/blackhole      |
| **Kube-monkey**  | Random pod termination in Kubernetes             |

---

## üé¨ Example Chaos Experiment: Kubernetes Pod Kill

### Using `LitmusChaos` on a Kubernetes Cluster

#### Step 1: Install Litmus

```bash
kubectl apply -f https://litmuschaos.github.io/litmus/litmus-operator-v3.0.0.yaml
```

#### Step 2: Create Chaos Experiment

```yaml
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: pod-kill
  namespace: litmus
spec:
  appinfo:
    appns: "golden-signal-ns"
    applabel: "app=golden-signal"
    appkind: "deployment"
  chaosServiceAccount: litmus-admin
  experiments:
    - name: pod-delete
```

#### Step 3: Trigger Chaos

```bash
kubectl create -f chaosengine.yaml
```

#### Step 4: Observe in Grafana/Prometheus

- Latency ‚Üë ?
- Error rate ‚Üë ?
- SLO burn rate ‚Üë ?
- Did auto-scaling or fallback kick in?

---

## üìà Measure Success

| Metric                     | Good Sign?              |
|----------------------------|--------------------------|
| Alert fired in < 1 min     | ‚úÖ Yes                   |
| SLO burn within budget     | ‚úÖ Yes                   |
| Auto-heal triggered        | ‚úÖ Yes                   |
| Manual intervention needed | ‚ùå No (bad)              |
| User impact?               | ‚ùå No (great!)           |

---

## üß† Advanced Practices

- Combine chaos with **canary deployments**
- Link chaos to **burn-rate alerts** for active SLO evaluation
- Run in **pre-prod daily** and **prod monthly** with strict guardrails
- Use **chaos tagging** in your observability dashboards

---

## üß© Real-World Example Use Cases

| Company    | What They Did                                   | Outcome                  |
|------------|--------------------------------------------------|--------------------------|
| Netflix    | Built Simian Army (Chaos Monkey, etc.)           | Industry standard        |
| LinkedIn   | DNS chaos tests with synthetic monitoring        | Improved routing config  |
| Shopify    | Killed k8s pods & DNS for cart service           | Validated auto-recovery  |
| Slack      | Injected latency on internal RPCs                | Reduced cascading failures|

---

## üß∞ Sample CI/CD Step for Weekly Chaos

```yaml
- name: Run Weekly Chaos on Cart Service
  run: |
    kubectl apply -f chaos/pod-delete-engine.yaml
    sleep 300
    ./scripts/check-slo-burn.sh
```

---

## üìÅ Learning Tasks for You

| Task | Description |
|------|-------------|
| ‚úÖ Install LitmusChaos in a test cluster |
| ‚úÖ Run a pod-kill or network latency experiment |
| ‚úÖ Connect it to Prometheus to track SLO burn |
| ‚úÖ Build a Grafana dashboard with chaos tag |
| ‚úÖ Document steady state & fallback behavior |